{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HL2nBeD7fAc",
        "outputId": "e274e8e4-ab55-4528-989d-adf8ce7e31fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: '#'\n",
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "                                              0.0/681.2 kB ? eta -:--:--\n",
            "     -                                     30.7/681.2 kB 640.0 kB/s eta 0:00:02\n",
            "     -                                     30.7/681.2 kB 640.0 kB/s eta 0:00:02\n",
            "     ----                                  81.9/681.2 kB 573.4 kB/s eta 0:00:02\n",
            "     -----                                112.6/681.2 kB 652.2 kB/s eta 0:00:01\n",
            "     ----------                           194.6/681.2 kB 841.6 kB/s eta 0:00:01\n",
            "     ------------                         235.5/681.2 kB 846.9 kB/s eta 0:00:01\n",
            "     ------------------------               440.3/681.2 kB 1.4 MB/s eta 0:00:01\n",
            "     ---------------------------            501.8/681.2 kB 1.4 MB/s eta 0:00:01\n",
            "     -----------------------------------    634.9/681.2 kB 1.5 MB/s eta 0:00:01\n",
            "     -------------------------------------- 681.2/681.2 kB 1.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: PyYAML in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py): started\n",
            "  Building wheel for pyngrok (setup.py): finished with status 'done'\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19897 sha256=04ef128e2c3a6aedc906c7631bc18b703138545afc051c75fc9c619ad28f1755\n",
            "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b6\\2f\\3d\\4957f583fdfd1c359843d2e57981c634692c579788b2dfc088\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: FastAPI in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.100.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from FastAPI) (2.0.3)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from FastAPI) (0.27.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from FastAPI) (4.6.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->FastAPI) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->FastAPI) (2.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->FastAPI) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->FastAPI) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->FastAPI) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask[async]\n",
            "  Downloading flask-2.3.3-py3-none-any.whl (96 kB)\n",
            "                                              0.0/96.1 kB ? eta -:--:--\n",
            "     --------------------------------------   92.2/96.1 kB 1.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 96.1/96.1 kB 1.8 MB/s eta 0:00:00\n",
            "Collecting Werkzeug>=2.3.7 (from flask[async])\n",
            "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
            "                                              0.0/242.2 kB ? eta -:--:--\n",
            "     ---------------------------            174.1/242.2 kB 5.3 MB/s eta 0:00:01\n",
            "     -------------------------------------- 242.2/242.2 kB 4.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask[async]) (3.1.2)\n",
            "Collecting itsdangerous>=2.1.2 (from flask[async])\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click>=8.1.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask[async]) (8.1.5)\n",
            "Collecting blinker>=1.6.2 (from flask[async])\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting asgiref>=3.2 (from flask[async])\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1.3->flask[async]) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=3.1.2->flask[async]) (2.1.3)\n",
            "Installing collected packages: Werkzeug, itsdangerous, blinker, asgiref, flask\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 2.3.6\n",
            "    Uninstalling Werkzeug-2.3.6:\n",
            "      Successfully uninstalled Werkzeug-2.3.6\n",
            "Successfully installed Werkzeug-2.3.7 asgiref-3.7.2 blinker-1.6.2 flask-2.3.3 itsdangerous-2.1.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required package for running Flask on Google Colab\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok\n",
        "!pip install FastAPI\n",
        "!pip install flask[async]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQGG0kYOLLot",
        "outputId": "454b1f3f-68f9-48c2-a70d-4a0357251b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1191, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1191 (delta 2), reused 6 (delta 2), pack-reused 1185\u001b[K\n",
            "Receiving objects: 100% (1191/1191), 74.22 MiB | 34.24 MiB/s, done.\n",
            "Resolving deltas: 100% (513/513), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKttoHxJLQCU",
        "outputId": "7dd3d3e0-d6bd-4099-e6cb-9d75095d068d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 10)) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 11)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 12)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 13)) (4.66.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 17)) (2.12.3)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 21)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 22)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov7/requirements.txt (line 35)) (5.9.5)\n",
            "Collecting thop (from -r /content/yolov7/requirements.txt (line 36))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r /content/yolov7/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov7/requirements.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov7/requirements.txt (line 9)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov7/requirements.txt (line 9)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov7/requirements.txt (line 9)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (16.0.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (3.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (2.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (0.41.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /content/yolov7/requirements.txt (line 21)) (2023.3)\n",
            "Collecting jedi>=0.16 (from ipython->-r /content/yolov7/requirements.txt (line 34))\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r /content/yolov7/requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r /content/yolov7/requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r /content/yolov7/requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/yolov7/requirements.txt (line 34)) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r /content/yolov7/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r /content/yolov7/requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.19.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/yolov7/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em2gAIzJKMBD"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import Response\n",
        "import os\n",
        "import shutil\n",
        "from subprocess import Popen\n",
        "# from arg_parsers import parse_args\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, './yolov7')\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTRggoCqyGZW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Setup and cleanup code to get the data zip files from Google Drive,\n",
        "and extract them for use from this Google Colab Notebook.\n",
        "\"\"\"\n",
        "def extractzip(zip_path, extract_path):\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  # print('zipfile: ', zip_path)\n",
        "  # print('extract path: ', extract_path)\n",
        "\n",
        "  os.makedirs(extract_path, exist_ok = True)\n",
        "\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "def setup_data():\n",
        "  # MOUNT_PATH's value is where the drive gets mounted by convention.\n",
        "  # From there onwards, the file paths point to where the zip files are on\n",
        "  # my Google Drive.\n",
        "  # The zip file will be extracted to EXTRACT_PATH. We can then see in\n",
        "  # colab using the Files view on the left.\n",
        "  MOUNT_PATH       = \"/content/drive\"\n",
        "  BDD_ZIPFILE_PATH = MOUNT_PATH + \"/MyDrive/AIML_HYD_20/Capstone_Project/FinalWeights/best.pt\"\n",
        "  EXTRACT_PATH     = \"/content/yolov7\"\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount(MOUNT_PATH)\n",
        "  shutil.copy(BDD_ZIPFILE_PATH, EXTRACT_PATH)\n",
        "  drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEtvC-2OyJFz",
        "outputId": "6cb6e264-a984-4ff2-c08e-d0bc95d6238e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "setup_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_03GjX_KDhU"
      },
      "outputs": [],
      "source": [
        "def read(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    return lines[0]\n",
        "\n",
        "def parse_args():\n",
        "    opt = {\n",
        "        'weights'     : '/content/yolov7/best.pt',\n",
        "        'source'      : \"\",  # file/folder, 0 for webcam\n",
        "        'img_size'    : 640,\n",
        "        'conf_thres'  : 0.25,\n",
        "        'iou_thres'   : 0.45,\n",
        "        'device'      : '',\n",
        "        'view_img'    : False,\n",
        "        'save_txt'    : False,\n",
        "        'save_conf'   : False,\n",
        "        'nosave'      : False,\n",
        "        'classes'     : None,\n",
        "        'agnostic_nms': False,\n",
        "        'augment'     : False,\n",
        "        'update'      : False,\n",
        "        'project'     : 'runs/detect',\n",
        "        'name'        : 'exp',\n",
        "        'exist_ok'    : False,\n",
        "        'no_trace'    : False,\n",
        "    }\n",
        "\n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQHR--WiKDj_",
        "outputId": "eb1b7ef8-03bc-47c4-effc-3273b20e627f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "opt = None\n",
        "source, model, stride, imgsz, device, half, view_img, save_txt, save_dir, modelc, classify = None, None, None, None, None, None, None, None, None, None, None\n",
        "opt = parse_args()\n",
        "\n",
        "def yolo_load():\n",
        "    global model, stride, imgsz, device, half, view_img, save_txt, save_dir, modelc, classify\n",
        "    weights, view_img, save_txt, imgsz, trace = opt['weights'], opt['view_img'], opt['save_txt'], opt['img_size'], not opt['no_trace']\n",
        "\n",
        "    # Directories\n",
        "    save_dir = Path(increment_path(Path(opt['project']) / opt['name'], exist_ok=opt['exist_ok']))  # increment run\n",
        "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "    # Initialize\n",
        "    set_logging()\n",
        "    device = select_device(opt['device'])\n",
        "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "    # Load model\n",
        "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "\n",
        "    if trace:\n",
        "        model = TracedModel(model, device, opt['img_size'])\n",
        "\n",
        "    if half:\n",
        "        model.half()  # to FP16\n",
        "\n",
        "    # Second-stage classifier\n",
        "    classify = False\n",
        "    if classify:\n",
        "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
        "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "    # return model, stride, imgsz, device, half, view_img, save_txt, save_dir, modelc, classify\n",
        "\n",
        "\n",
        "def yolo_detect(input_image_path = \"\"):\n",
        "    global model, stride, imgsz, device, half, view_img, save_txt, save_dir, modelc, classify\n",
        "\n",
        "    # Directories\n",
        "    save_dir = Path(increment_path(Path(opt['project']) / opt['name'], exist_ok=opt['exist_ok']))  # increment run\n",
        "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "    source = input_image_path\n",
        "    # source = source\n",
        "\n",
        "    save_img = not opt['nosave'] and not source.endswith('.txt')  # save inference images\n",
        "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "\n",
        "    # Set Dataloader\n",
        "    vid_path, vid_writer = None, None\n",
        "    if webcam:\n",
        "        view_img = check_imshow()\n",
        "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "    else:\n",
        "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "\n",
        "    # Get names and colors\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "\n",
        "    # Run inference\n",
        "    if device.type != 'cpu':\n",
        "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "    old_img_w = old_img_h = imgsz\n",
        "    old_img_b = 1\n",
        "\n",
        "    t0 = time.time()\n",
        "    for path, img, im0s, vid_cap in dataset:\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if img.ndimension() == 3:\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        # Warmup\n",
        "        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
        "            old_img_b = img.shape[0]\n",
        "            old_img_h = img.shape[2]\n",
        "            old_img_w = img.shape[3]\n",
        "            for i in range(3):\n",
        "                model(img, augment=opt['augment'])[0]\n",
        "\n",
        "        # Inference\n",
        "        t1 = time_synchronized()\n",
        "        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
        "            pred = model(img, augment=opt['augment'])[0]\n",
        "        t2 = time_synchronized()\n",
        "\n",
        "        # Apply NMS\n",
        "        pred = non_max_suppression(pred, opt['conf_thres'], opt['iou_thres'], classes=opt['classes'], agnostic=opt['agnostic_nms'])\n",
        "        t3 = time_synchronized()\n",
        "\n",
        "        # Apply Classifier\n",
        "        if classify:\n",
        "            pred = apply_classifier(pred, modelc, img, im0s)\n",
        "\n",
        "        # Process detections\n",
        "        for i, det in enumerate(pred):  # detections per image\n",
        "            if webcam:  # batch_size >= 1\n",
        "                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
        "            else:\n",
        "                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
        "\n",
        "            p = Path(p)  # to Path\n",
        "            save_path = str(save_dir / p.name)  # img.jpg\n",
        "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "            if len(det):\n",
        "                # Rescale boxes from img_size to im0 size\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Print results\n",
        "                for c in det[:, -1].unique():\n",
        "                    n = (det[:, -1] == c).sum()  # detections per class\n",
        "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "                # Write results\n",
        "                for *xyxy, conf, cls in reversed(det):\n",
        "                    if save_txt:  # Write to file\n",
        "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                        line = (cls, *xywh, conf) if opt['save_conf'] else (cls, *xywh)  # label format\n",
        "                        with open(txt_path + '.txt', 'a') as f:\n",
        "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "                    if save_img or view_img:  # Add bbox to image\n",
        "                        label = f'{names[int(cls)]} {conf:.2f}'\n",
        "                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
        "\n",
        "            # Print time (inference + NMS)\n",
        "            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS', flush=True)\n",
        "\n",
        "            # Stream results\n",
        "            if view_img:\n",
        "                cv2.imshow(str(p), im0)\n",
        "                cv2.waitKey(1)  # 1 millisecond\n",
        "\n",
        "            # Save results (image with detections)\n",
        "            if save_img:\n",
        "                if dataset.mode == 'image':\n",
        "                    cv2.imwrite(save_path, im0)\n",
        "                    print(f\" The image with the result is saved in: {save_path}\")\n",
        "                else:  # 'video' or 'stream'\n",
        "                    if vid_path != save_path:  # new video\n",
        "                        vid_path = save_path\n",
        "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
        "                            vid_writer.release()  # release previous video writer\n",
        "                        if vid_cap:  # video\n",
        "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "                        else:  # stream\n",
        "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
        "                            save_path += '.mp4'\n",
        "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "                    vid_writer.write(im0)\n",
        "\n",
        "    if save_txt or save_img:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        #print(f\"Results saved to {save_dir}{s}\")\n",
        "\n",
        "    print(f'Done. ({time.time() - t0:.3f}s)')\n",
        "\n",
        "\n",
        "yolo_load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfPuJIc8JdFS",
        "outputId": "5eb5f666-4efa-4a9f-ff53-5d5688813d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-25T19:24:24+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://3adb-34-32-198-179.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:24:37] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'weights': '/content/yolov7/best.pt', 'source': '', 'img_size': 640, 'conf_thres': 0.25, 'iou_thres': 0.45, 'device': '', 'view_img': False, 'save_txt': False, 'save_conf': False, 'nosave': False, 'classes': None, 'agnostic_nms': False, 'augment': False, 'update': False, 'project': 'runs/detect', 'name': 'exp', 'exist_ok': False, 'no_trace': False}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:24:38] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:24:50] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:24:50] \"GET /content/uploaded_images/ac9be3fe-790d1f8e.jpeg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:24:50] \"GET /content/runs/detect/exp/ac9be3fe-790d1f8e.jpeg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:25:06] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:25:29] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:25:30] \"\u001b[35m\u001b[1mGET /content/uploaded_images/traffic.mp4 HTTP/1.1\u001b[0m\" 206 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:25:34] \"GET /content/runs/detect/exp/traffic.mp4 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Aug/2023 19:26:17] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from flask import Flask, request, render_template, Response\n",
        "from werkzeug.utils import secure_filename\n",
        "from pyngrok import ngrok  # Import ngrok package\n",
        "\n",
        "# Set up Flask app\n",
        "app = Flask(__name__, static_folder='/content')\n",
        "\n",
        "# UPLOAD_FOLDER = '/content/uploaded_images'\n",
        "# app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "# app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg', 'gif', 'mp4'}\n",
        "\n",
        "# Define allowed file extensions\n",
        "# def allowed_file(filename):\n",
        "#     return '.' in filename and \\\n",
        "#            filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']\n",
        "\n",
        "# this is our start page\n",
        "@app.route(\"/\")\n",
        "async def homepage():\n",
        "    html_content = f\"\"\"\n",
        "        <html>\n",
        "            <body style=\"text-align:center\">\n",
        "                <h1>Road Object Detection</h1>\n",
        "                <p>This page serves a \"custom\" <a href=\"https://arxiv.org/abs/2207.02696\">Yolov7 model</a> for Road Object Detection.</p>\n",
        "                <p>It has been trained on the <a href=\"https://bdd-data.berkeley.edu/\">BDD100K dataset</a>.</p>\n",
        "                <p>Choose an image or video, and click Detect.</p>\n",
        "                <form action=\"/detect\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "                    <input type=\"file\" name=\"inputfile\">\n",
        "                    <input type=\"submit\" value=\"Detect\">\n",
        "                </form>\n",
        "            </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "    print(opt)\n",
        "    global model, stride, imgsz, device, half, view_img, save_txt, save_dir, modelc, classify\n",
        "    # model, stride, imgsz, device, half, view_img, save_txt, save_dir, modelc, classify =\n",
        "    return html_content\n",
        "\n",
        "@app.route(\"/detect\", methods=['POST'])\n",
        "async def detect():\n",
        "    # ------------------------------------------------------\n",
        "    # 1. proceed only if the file has an accepted extension\n",
        "    video     = False\n",
        "    inputfile = request.files['inputfile']\n",
        "    fname     = secure_filename(inputfile.filename)\n",
        "\n",
        "    if fname.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        video = False\n",
        "    elif fname.endswith(('mp4')):\n",
        "        video = True\n",
        "    else:\n",
        "        html_content = f\"\"\"\n",
        "        <html>\n",
        "            <body>\n",
        "                <p><b>error: unsupported format.</b></p>\n",
        "                <p>Supported formats are .jpg, .jpeg, .png, .mp4</p>\n",
        "            </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "        return html_content\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 2. upload input file\n",
        "    upload_folder = \"/content/uploaded_images\"\n",
        "    os.makedirs(upload_folder, exist_ok=True)\n",
        "    input_file_path = os.path.join(upload_folder, fname)\n",
        "    inputfile.save(input_file_path)\n",
        "    # ------------------------------------------------------\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 3. run detection on the input file.\n",
        "    #\n",
        "    # To make it easy to report results we will clean up the results\n",
        "    # folder if it exits.\n",
        "    # Note that we should have already cloned the yolov7 repo at the\n",
        "    # current folder. Therefore the results will be emitted to:\n",
        "    # \"yolov7/runs\"\n",
        "    runs_folder = \"/content/runs\"\n",
        "    if os.path.exists(runs_folder):\n",
        "        process = Popen([\"rm\", \"-r\", runs_folder])\n",
        "        process.wait()  # Wait for the process to complete\n",
        "\n",
        "    # we will create a log text file and redirect stdout there.\n",
        "    # The detections will be reported in this text filem\n",
        "    log_folder    = \"logs\"\n",
        "    log_filename  = \"log.txt\"\n",
        "    os.makedirs(log_folder, exist_ok = True)\n",
        "    log_file_path = os.path.join(log_folder, log_filename)\n",
        "    logfile       = open(log_file_path, \"w\")\n",
        "\n",
        "    import sys\n",
        "    sys.stdout = logfile\n",
        "\n",
        "    # wt_file = \"yolov7/best.pt\"\n",
        "    # process = Popen([\"python\", \"yolov7/detect.py\", \"--weights\", wt_file,\n",
        "    #                   \"--source\", input_file_path])\n",
        "    # process.wait()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        yolo_detect(input_file_path)\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 4. get path to the predicted file, and to the results.\n",
        "    output_folder        = runs_folder + \"/detect/exp\"\n",
        "    prediction_filename  = os.listdir(output_folder)[0]\n",
        "    prediction_file_path = os.path.join(output_folder, prediction_filename)\n",
        "\n",
        "    results = read(log_file_path)\n",
        "    # ------------------------------------------------------\n",
        "\n",
        "    # from fastapi.staticfiles import StaticFiles\n",
        "    # app.mount(\"uploaded_images\", StaticFiles(directory=\"uploaded_images\"), name=\"uploaded_images\")\n",
        "    # app.mount(\"runs\", StaticFiles(directory=\"runs\"), name=\"runs\")\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 5. return the predicted file.\n",
        "    if video:\n",
        "        html_content = f\"\"\"\n",
        "        <html>\n",
        "            <body>\n",
        "                <p><b>Chosen video: </b>{fname}</p>\n",
        "                <video controls>\n",
        "                    <source src=\"{input_file_path}\">\n",
        "                </video>\n",
        "                <br>\n",
        "                <br>\n",
        "                <p><b>Please download video to view detections: </b>\n",
        "                    <a href=\"{prediction_file_path}\" download>Download Video</a>\n",
        "                </p>\n",
        "            </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "        return html_content\n",
        "\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "        <body>\n",
        "            <p><b>Chosen image: </b>{fname}</p>\n",
        "            <img id=\"image1\" src=\"{input_file_path}\" alt=\"Image will display here.\">\n",
        "            <br>\n",
        "            <br>\n",
        "            <p><b>Image with detections:</b> {results}</p>\n",
        "            <img id=\"image2\" src=\"{prediction_file_path}\" alt=\"Image will display here.\">\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return html_content\n",
        "    # ------------------------------------------------------\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "# Start ngrok tunnel with your authtoken\n",
        "authtoken = \"2SjjXeH0EcSRIVmHFOkD0CINQWs_7hUDVDn8tLhCZBKWonUR\"  # Replace with your ngrok authtoken\n",
        "ngrok.set_auth_token(authtoken)\n",
        "tunnel = ngrok.connect(5000)\n",
        "print(f\"Public URL: {tunnel.public_url}\")\n",
        "\n",
        "# Run the Flask app\n",
        "app.run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
